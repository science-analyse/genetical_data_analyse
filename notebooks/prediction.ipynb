{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Expression Prediction: ALL vs AML Classification\n",
    "## Model Deployment and Testing\n",
    "\n",
    "This notebook loads trained models and provides prediction functionality for classifying gene expression data as ALL (Acute Lymphoblastic Leukemia) or AML (Acute Myeloid Leukemia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:55.137829Z",
     "iopub.status.busy": "2025-11-30T17:46:55.137561Z",
     "iopub.status.idle": "2025-11-30T17:46:55.444962Z",
     "shell.execute_reply": "2025-11-30T17:46:55.444705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:55.446418Z",
     "iopub.status.busy": "2025-11-30T17:46:55.446237Z",
     "iopub.status.idle": "2025-11-30T17:46:56.011195Z",
     "shell.execute_reply": "2025-11-30T17:46:56.010927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Model: SVM (RBF)\n",
      "Test Accuracy: 0.6176\n",
      "CV Accuracy: 0.9750\n",
      "\n",
      "Number of features (genes): 50\n",
      "\n",
      "Top 10 genes used:\n",
      "  1. Leukotriene C4 synthase (LTC4S) gene\n",
      "  2. Zyxin\n",
      "  3. FAH Fumarylacetoacetate\n",
      "  4. LYN V-yes-1 Yamaguchi sarcoma viral related oncogene homolog\n",
      "  5. LEPR Leptin receptor\n",
      "  6. CD33 CD33 antigen (differentiation antigen)\n",
      "  7. Liver mRNA for interferon-gamma inducing factor(IGIF)\n",
      "  8. PRG1 Proteoglycan 1; secretory granule\n",
      "  9. GB DEF = Homeodomain protein HoxA9 mRNA\n",
      "  10. DF D component of complement (adipsin)\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "models_dir = '../models'\n",
    "\n",
    "# Load model artifacts\n",
    "model = joblib.load(f'{models_dir}/best_model_svm_rbf.pkl')\n",
    "scaler = joblib.load(f'{models_dir}/scaler.pkl')\n",
    "top_genes_indices = joblib.load(f'{models_dir}/top_genes_indices.pkl')\n",
    "gene_metadata = joblib.load(f'{models_dir}/gene_metadata.pkl')\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"\\nModel: {gene_metadata['model_name']}\")\n",
    "print(f\"Test Accuracy: {gene_metadata['test_accuracy']:.4f}\")\n",
    "print(f\"CV Accuracy: {gene_metadata['cv_accuracy']:.4f}\")\n",
    "print(f\"\\nNumber of features (genes): {gene_metadata['n_features']}\")\n",
    "print(f\"\\nTop 10 genes used:\")\n",
    "for i, gene_name in enumerate(gene_metadata['top_genes_names'][:10], 1):\n",
    "    print(f\"  {i}. {gene_name[:70]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:56.025981Z",
     "iopub.status.busy": "2025-11-30T17:46:56.025815Z",
     "iopub.status.idle": "2025-11-30T17:46:56.053739Z",
     "shell.execute_reply": "2025-11-30T17:46:56.053503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded: 34 samples, 7129 genes\n",
      "\n",
      "Class distribution:\n",
      "ALL    20\n",
      "AML    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_df = pd.read_csv('../data/data_set_ALL_AML_independent.csv')\n",
    "labels_df = pd.read_csv('../data/actual.csv')\n",
    "\n",
    "# Get expression columns\n",
    "gene_info_cols = ['Gene Description', 'Gene Accession Number']\n",
    "test_cols = test_df.columns.tolist()\n",
    "test_expr_cols = [col for col in test_cols if col not in gene_info_cols and 'call' not in col.lower()]\n",
    "\n",
    "# Extract expression matrix\n",
    "X_test = test_df[test_expr_cols].T\n",
    "\n",
    "# Get labels for test samples\n",
    "test_labels = labels_df[labels_df['patient'] > 38].copy()\n",
    "y_test = test_labels['cancer'].values\n",
    "\n",
    "print(f\"Test data loaded: {X_test.shape[0]} samples, {X_test.shape[1]} genes\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:56.055123Z",
     "iopub.status.busy": "2025-11-30T17:46:56.054865Z",
     "iopub.status.idle": "2025-11-30T17:46:56.057723Z",
     "shell.execute_reply": "2025-11-30T17:46:56.057520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def predict_cancer_type(gene_expression_data: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Predict cancer type from gene expression data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gene_expression_data : np.ndarray\n",
    "        Array of gene expression values (must have 7129 genes)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Prediction results with probabilities\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if gene_expression_data.shape[0] != 7129:\n",
    "        raise ValueError(f\"Expected 7129 genes, got {gene_expression_data.shape[0]}\")\n",
    "    \n",
    "    # Select top genes\n",
    "    X_selected = gene_expression_data[top_genes_indices].reshape(1, -1)\n",
    "    \n",
    "    # Scale features\n",
    "    X_scaled = scaler.transform(X_selected)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X_scaled)[0]\n",
    "    probabilities = model.predict_proba(X_scaled)[0]\n",
    "    \n",
    "    # Get class labels\n",
    "    classes = model.classes_\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'prediction': prediction,\n",
    "        'confidence': float(max(probabilities)),\n",
    "        'probabilities': {\n",
    "            classes[0]: float(probabilities[0]),\n",
    "            classes[1]: float(probabilities[1])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Prediction function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Predictions on Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:56.058830Z",
     "iopub.status.busy": "2025-11-30T17:46:56.058737Z",
     "iopub.status.idle": "2025-11-30T17:46:56.062292Z",
     "shell.execute_reply": "2025-11-30T17:46:56.062088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predictions on sample data:\n",
      "================================================================================\n",
      "\n",
      "Sample 1:\n",
      "  True Label:     ALL\n",
      "  Prediction:     ALL\n",
      "  Confidence:     95.37%\n",
      "  ALL Probability: 95.37%\n",
      "  AML Probability: 4.63%\n",
      "  Correct:        ✓\n",
      "\n",
      "Sample 2:\n",
      "  True Label:     ALL\n",
      "  Prediction:     ALL\n",
      "  Confidence:     80.66%\n",
      "  ALL Probability: 80.66%\n",
      "  AML Probability: 19.34%\n",
      "  Correct:        ✓\n",
      "\n",
      "Sample 3:\n",
      "  True Label:     ALL\n",
      "  Prediction:     AML\n",
      "  Confidence:     76.09%\n",
      "  ALL Probability: 23.91%\n",
      "  AML Probability: 76.09%\n",
      "  Correct:        ✗\n",
      "\n",
      "Sample 4:\n",
      "  True Label:     ALL\n",
      "  Prediction:     ALL\n",
      "  Confidence:     94.23%\n",
      "  ALL Probability: 94.23%\n",
      "  AML Probability: 5.77%\n",
      "  Correct:        ✓\n",
      "\n",
      "Sample 5:\n",
      "  True Label:     ALL\n",
      "  Prediction:     ALL\n",
      "  Confidence:     98.08%\n",
      "  ALL Probability: 98.08%\n",
      "  AML Probability: 1.92%\n",
      "  Correct:        ✓\n"
     ]
    }
   ],
   "source": [
    "# Test on first 5 samples from test set\n",
    "print(\"Testing predictions on sample data:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(min(5, len(X_test))):\n",
    "    sample_data = X_test.iloc[i].values\n",
    "    true_label = y_test[i]\n",
    "    \n",
    "    result = predict_cancer_type(sample_data)\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  True Label:     {true_label}\")\n",
    "    print(f\"  Prediction:     {result['prediction']}\")\n",
    "    print(f\"  Confidence:     {result['confidence']:.2%}\")\n",
    "    print(f\"  ALL Probability: {result['probabilities']['ALL']:.2%}\")\n",
    "    print(f\"  AML Probability: {result['probabilities']['AML']:.2%}\")\n",
    "    print(f\"  Correct:        {'✓' if result['prediction'] == true_label else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:56.063289Z",
     "iopub.status.busy": "2025-11-30T17:46:56.063209Z",
     "iopub.status.idle": "2025-11-30T17:46:56.073498Z",
     "shell.execute_reply": "2025-11-30T17:46:56.073301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance on Test Set:\n",
      "================================================================================\n",
      "Total Samples:     34\n",
      "Correct:           21\n",
      "Incorrect:         13\n",
      "Accuracy:          61.76%\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred ALL  Pred AML\n",
      "True ALL        14         6\n",
      "True AML         7         7\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALL       0.67      0.70      0.68        20\n",
      "         AML       0.54      0.50      0.52        14\n",
      "\n",
      "    accuracy                           0.62        34\n",
      "   macro avg       0.60      0.60      0.60        34\n",
      "weighted avg       0.61      0.62      0.62        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on entire test set\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    sample_data = X_test.iloc[i].values\n",
    "    result = predict_cancer_type(sample_data)\n",
    "    predictions.append(result['prediction'])\n",
    "    true_labels.append(y_test[i])\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = sum([1 for i in range(len(predictions)) if predictions[i] == true_labels[i]])\n",
    "accuracy = correct / len(predictions)\n",
    "\n",
    "print(\"\\nModel Performance on Test Set:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Samples:     {len(predictions)}\")\n",
    "print(f\"Correct:           {correct}\")\n",
    "print(f\"Incorrect:         {len(predictions) - correct}\")\n",
    "print(f\"Accuracy:          {accuracy:.2%}\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions, labels=['ALL', 'AML'])\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm, index=['True ALL', 'True AML'], columns=['Pred ALL', 'Pred AML']))\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Single Sample Prediction Example\n",
    "\n",
    "This demonstrates how to make a prediction for a single patient's gene expression profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:56.074564Z",
     "iopub.status.busy": "2025-11-30T17:46:56.074474Z",
     "iopub.status.idle": "2025-11-30T17:46:56.077153Z",
     "shell.execute_reply": "2025-11-30T17:46:56.076947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Sample #1\n",
      "================================================================================\n",
      "\n",
      "Prediction Results:\n",
      "  Predicted Cancer Type: ALL\n",
      "  Confidence Level:      95.37%\n",
      "\n",
      "Detailed Probabilities:\n",
      "  ALL: 0.9537 (95.37%)\n",
      "  AML: 0.0463 (4.63%)\n",
      "\n",
      "Top 5 Gene Expression Values Used:\n",
      "  1. Leukotriene C4 synthase (LTC4S) gene: 1122.00\n",
      "  2. Zyxin: 178.00\n",
      "  3. FAH Fumarylacetoacetate: 627.00\n",
      "  4. LYN V-yes-1 Yamaguchi sarcoma viral related oncogene homolog: 164.00\n",
      "  5. LEPR Leptin receptor: 465.00\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict for a specific sample\n",
    "sample_index = 0  # Change this to test different samples\n",
    "sample_patient = X_test.iloc[sample_index]\n",
    "\n",
    "print(f\"Patient Sample #{sample_index + 1}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Make prediction\n",
    "result = predict_cancer_type(sample_patient.values)\n",
    "\n",
    "print(f\"\\nPrediction Results:\")\n",
    "print(f\"  Predicted Cancer Type: {result['prediction']}\")\n",
    "print(f\"  Confidence Level:      {result['confidence']:.2%}\")\n",
    "print(f\"\\nDetailed Probabilities:\")\n",
    "for cancer_type, prob in result['probabilities'].items():\n",
    "    print(f\"  {cancer_type}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "\n",
    "# Show top contributing genes for this prediction\n",
    "print(f\"\\nTop 5 Gene Expression Values Used:\")\n",
    "selected_genes = sample_patient.values[top_genes_indices]\n",
    "for i in range(5):\n",
    "    gene_name = gene_metadata['top_genes_names'][i]\n",
    "    expression_value = selected_genes[i]\n",
    "    print(f\"  {i+1}. {gene_name[:60]}: {expression_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Prediction Function for API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:46:56.078243Z",
     "iopub.status.busy": "2025-11-30T17:46:56.078141Z",
     "iopub.status.idle": "2025-11-30T17:46:56.080561Z",
     "shell.execute_reply": "2025-11-30T17:46:56.080380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction module saved to: predictor.py\n",
      "This file can be imported by the FastAPI application\n"
     ]
    }
   ],
   "source": [
    "# Save prediction function as a module\n",
    "prediction_code = '''\n",
    "import numpy as np\n",
    "import joblib\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load model artifacts (done once at startup)\n",
    "models_dir = 'models'\n",
    "model = joblib.load(f'{models_dir}/best_model_svm_rbf.pkl')\n",
    "scaler = joblib.load(f'{models_dir}/scaler.pkl')\n",
    "top_genes_indices = joblib.load(f'{models_dir}/top_genes_indices.pkl')\n",
    "gene_metadata = joblib.load(f'{models_dir}/gene_metadata.pkl')\n",
    "\n",
    "def predict_cancer_type(gene_expression_data: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Predict cancer type from gene expression data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gene_expression_data : np.ndarray or list\n",
    "        Array of gene expression values (must have 7129 genes)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Prediction results with probabilities\n",
    "    \"\"\"\n",
    "    # Convert to numpy array if needed\n",
    "    if isinstance(gene_expression_data, list):\n",
    "        gene_expression_data = np.array(gene_expression_data)\n",
    "    \n",
    "    # Validate input\n",
    "    if gene_expression_data.shape[0] != 7129:\n",
    "        raise ValueError(f\"Expected 7129 genes, got {gene_expression_data.shape[0]}\")\n",
    "    \n",
    "    # Select top genes\n",
    "    X_selected = gene_expression_data[top_genes_indices].reshape(1, -1)\n",
    "    \n",
    "    # Scale features\n",
    "    X_scaled = scaler.transform(X_selected)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X_scaled)[0]\n",
    "    probabilities = model.predict_proba(X_scaled)[0]\n",
    "    \n",
    "    # Get class labels\n",
    "    classes = model.classes_\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'prediction': prediction,\n",
    "        'confidence': float(max(probabilities)),\n",
    "        'probabilities': {\n",
    "            classes[0]: float(probabilities[0]),\n",
    "            classes[1]: float(probabilities[1])\n",
    "        },\n",
    "        'model_info': {\n",
    "            'name': gene_metadata['model_name'],\n",
    "            'accuracy': gene_metadata['test_accuracy'],\n",
    "            'n_features': gene_metadata['n_features']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_model_info() -> Dict[str, Any]:\n",
    "    \"\"\"Get information about the loaded model.\"\"\"\n",
    "    return {\n",
    "        'model_name': gene_metadata['model_name'],\n",
    "        'test_accuracy': gene_metadata['test_accuracy'],\n",
    "        'cv_accuracy': gene_metadata['cv_accuracy'],\n",
    "        'n_features': gene_metadata['n_features'],\n",
    "        'total_genes_required': 7129,\n",
    "        'top_genes': gene_metadata['top_genes_names']\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open('../predictor.py', 'w') as f:\n",
    "    f.write(prediction_code)\n",
    "\n",
    "print(\"Prediction module saved to: predictor.py\")\n",
    "print(\"This file can be imported by the FastAPI application\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading trained models and artifacts\n",
    "2. Making predictions on new gene expression data\n",
    "3. Evaluating model performance\n",
    "4. Exporting prediction functionality for deployment\n",
    "\n",
    "The prediction function can now be integrated into a FastAPI web application for production use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
